# Action Recognition with X3D

Проект по **распознаванию действий на видео** на основе архитектуры **X3D (PyTorchVideo)**.  
Включает полный пайплайн: **подготовка датасета → обучение → онлайн и офлайн инференс**.

---

##  Demo

Ниже показан пример работы модели на видео с наложенными предсказаниями действий:

![Action Recognition Demo](assets/demo.gif)

---

##  О проекте

классы (label):
- walk (ходьба)
- stand (обычная стойка)
- jump (прыжки)
- push-ups (отжимания)
- run (бег)
- squat (приседания)
- band (наклоны)
- other (любые другие движения, в тренировочных видео я махал руками, использовал удары ногой и делал потягивания)

- Модель: **X3D (spatiotemporal CNN)**
- Формат инференса: sliding window по видео
- Поддержка **CPU / GPU**
- Реализованы:
  - онлайн-инференс (real-time)
  - офлайн-инференс (video → video)
  - сглаживание предсказаний
  - контроль задержки реакции модели

Проект ориентирован на **реалистичное применение action recognition**, а не только офлайн-оценку.

---

## Закачка библиотек

```
pip install -r requirements.txt
```

##  Подготовка датасета

Код подготовки датасета:

```bash
python src/data/prepare_dataset.py
```

---

## Инференс

### Онлайн (real-time)
```bash
python inf/infer_online.py
```

### Офлайн (video → video)
```bash
python inf/infer_video.py
```

---

## Другие моменты

Разметка видеороликов была максимально кривой (не старался попадать в доли секунды и не совсем точно размечал некоторые движения) и делал я ее с помощью файла формата .csv с 4 столбцами (video, start_sec, end_sec, label). Обучал саму модель на платформе kaggle и финальные веса выгружал оттуда же (здесь я не оставил веса, можно просто запустить код в kaggle, я обучал на 20 эпохах, но RAM kaggle подводила.


